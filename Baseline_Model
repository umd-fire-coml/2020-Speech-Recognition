{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Baseline_Model","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP8Pwl+hsEh2XlnN0ykjo1h"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3NtrdDpvdXFt"},"source":["# Baseline Model\n","\n","This notebook is designed to test our generator and augmentation code with a real model. "]},{"cell_type":"code","metadata":{"id":"sf75_l4ffNEm","executionInfo":{"elapsed":1559924,"status":"ok","timestamp":1602961662941,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"78d1dc29-6c08-415f-f249-a5f12d752acb","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8E-fC4IKddR1"},"source":["## Install DeepSpeech and Get Pre-Trained Model\n","\n","We are using the DeepSpeech library to get a baseline for how a pre-trained English model on speech to text performs on our Amazing Grace dataset. More information on the model and how it can be used can be found here: https://deepspeech.readthedocs.io\n"]},{"cell_type":"code","metadata":{"id":"RVf5TyrTZr04","executionInfo":{"elapsed":32632,"status":"ok","timestamp":1602960130334,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"3a326d04-7bf0-4613-a62a-8f7593261d08","colab":{"base_uri":"https://localhost:8080/","height":275}},"source":["!pip install deepspeech-gpu\n","!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.pbmm\n","!curl -LO https://github.com/mozilla/DeepSpeech/releases/download/v0.8.1/deepspeech-0.8.1-models.scorer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting deepspeech-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/40/0db48175a3e438d81c6f1663962ee11255728b8fa82aad444efb0072aa49/deepspeech_gpu-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (19.9MB)\n","\u001b[K     |████████████████████████████████| 19.9MB 54.1MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-gpu) (1.18.5)\n","Installing collected packages: deepspeech-gpu\n","Successfully installed deepspeech-gpu-0.8.2\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   652  100   652    0     0   2479      0 --:--:-- --:--:-- --:--:--  2479\n","100  180M  100  180M    0     0  35.3M      0  0:00:05  0:00:05 --:--:-- 41.0M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   654  100   654    0     0   3353      0 --:--:-- --:--:-- --:--:--  3353\n","100  909M  100  909M    0     0  42.4M      0  0:00:21  0:00:21 --:--:-- 40.3M\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d7AKNh7yeLFG"},"source":["import deepspeech as ds\n","\n","model = ds.Model(\"deepspeech-0.8.1-models.pbmm\")\n","model.enableExternalScorer(\"deepspeech-0.8.1-models.scorer\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ch3BqzPoe36e"},"source":["## Create A Data Generator Object\n","\n","In the section below, we create a DataGenerator object that can be used to generate data from our Amazing Grace Dataset. The location of this dataset has been hardcoded for my own drive since not all files are merged to master yet, but in the future we could change the imdir path below to reflect the location in the data store. "]},{"cell_type":"code","metadata":{"id":"dG1-4F0ofKdQ","executionInfo":{"elapsed":964,"status":"ok","timestamp":1602961974159,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"c27d7995-2b99-4d91-9dd1-1882055469ee","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["%cd \"/content/drive/My Drive/Research/FIRE/2020-Speech-Recognition\"\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Research/FIRE/2020-Speech-Recognition\n","data_augmentor.py  Data_Visualization.ipynb  __pycache__\n","DataGenerator.py   generator_test.ipynb      README.md\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o8KrfrCjf3Pm","executionInfo":{"elapsed":19686,"status":"ok","timestamp":1602961997789,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"8eed66a3-072f-4260-f15a-37c0c39c52c5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","\n","imdir = \"/content/drive/My Drive/Datasets/amazing_grace/\"\n","file_list = [f for f in os.listdir(imdir) if os.path.isfile(os.path.join(imdir, f))]\n","print(len(file_list))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3832\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kNNjYiaufs6m"},"source":["import DataGenerator\n","from DataGenerator import DataGenerator\n","\n","dg = DataGenerator(imdir, file_list,[\"grace\"]*len(file_list),1,(1,len(file_list)), 1,1,True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"anmn_kRZJPBO"},"source":["### Generate a Sample of Data\n","\n","In the section below we get a sample of data using our DataGenerator object for the remaining tests below. We also convert our audio from float to int16 to meet the input requirements of the DeepSpeech model. "]},{"cell_type":"code","metadata":{"id":"7FnL0R0ng9Cn","executionInfo":{"elapsed":9789,"status":"ok","timestamp":1602962949392,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"1278017a-145f-4126-d331-4e756b0351e8","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["import numpy as np\n","\n","aud = dg.__getitem__()\n","aud_int = (aud * 32768).astype(\"int16\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["135917160_168710743.m4a\n","3058347\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"US9GbyIGEsE0"},"source":["Google Colab allows us to play audio within a notebook and the cell below does exactly that. We can't gaurantee the quality of the below rendition of Amazing Grace, but it plays Amazing Grace (i.e. our dataset and Data Generator are working as expected!). "]},{"cell_type":"code","metadata":{"id":"dZMOrk99lcN-","executionInfo":{"elapsed":15194,"status":"ok","timestamp":1602962957472,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"d3e1114e-e692-4b47-bdef-3025ad94345c","colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1_BJDpd9nKEKyBYbA35dUuKkcJ4zlzi4n"}},"source":["Audio(aud_int, rate=16000)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"-dmvWBWaIXBG"},"source":["## Create A Data Augmentation Object \n","\n","In the section below, we create a DataAugmentation object that can be used to augment data from our Amazing Grace Dataset. Currently, this class is built to work with only one file, but we may want to change this to allow for a class to work with any number of files and perform processing in batches."]},{"cell_type":"code","metadata":{"id":"4U1fBilyIxpz"},"source":["import DataAugmentation\n","from DataAugmentation import DataAugmentation\n","\n","da = DataAugmentation(data=aud[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-QQX1H0JqK3"},"source":["Let's also test our Data Augmentation code and see if it is working correctly as well."]},{"cell_type":"code","metadata":{"id":"60u8hCfGJpg8","executionInfo":{"status":"ok","timestamp":1602965451920,"user_tz":240,"elapsed":23573,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"}},"outputId":"cdf4fc3b-acb0-4efd-ea56-8785ceb01bf3","colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1iRLh7IGRwZpBhuGXo95l9BtyFcyvo3P8"}},"source":["aud_aug = []\n","aud_aug.append(da.change_pitch())\n","Audio(aud_aug[-1], rate=16000)"],"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"QFU5LyKpKfN_","executionInfo":{"status":"ok","timestamp":1602965451921,"user_tz":240,"elapsed":20773,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"}},"outputId":"7553d4e1-2a00-4470-ad6a-d4666bb4c4ad","colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1JwtmWqScQJdouVJYG1-CoP4pL__98TlF"}},"source":["aud_aug.append(da.change_speed())\n","Audio(aud_aug[-1], rate=16000)"],"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"6xy97QupKvpJ","executionInfo":{"status":"ok","timestamp":1602965451924,"user_tz":240,"elapsed":15251,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"}},"outputId":"1fb5cd07-1351-4a56-b23c-7b3ce8e5ae35","colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1ZnbSnf6coT2VOz6k0UzhixyY0RAgaQwJ"}},"source":["aud_aug.append(da.noise_injection())\n","Audio(aud_aug[-1], rate=16000)"],"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"nU2tWTvsK3Rk","executionInfo":{"status":"ok","timestamp":1602965527055,"user_tz":240,"elapsed":8400,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"}},"outputId":"2b362859-bd57-4a9b-baf3-d697c8428e5e","colab":{"base_uri":"https://localhost:8080/","height":52,"output_embedded_package_id":"1t2ZXvZxSeKA1lp-fQeO4U8vS_UbQ7qpm"}},"source":["aud_aug.append(da.shifting_time())\n","Audio(aud_aug[-1], rate=16000)"],"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"oVDkd4tcEGNK"},"source":["## Run DeepSpeech Model on Our Audio Sample\n","\n","In this section we run the DeepSpeech Model on our new int audio. "]},{"cell_type":"markdown","metadata":{"id":"NEkSgnI1FLUk"},"source":["The code below runs the DeepSpeech model on the sample above using the pretrained weights for the English language."]},{"cell_type":"markdown","metadata":{"id":"vr2N7ACdFWS6"},"source":["**Expected Output:**\n","\n","Amazing grace \n","How sweet the sound\n","That saved a wretch like me\n","I once was lost \n","But now I'm found\n","Was blind, but now I see\n","'Twas grace that taught \n","My heart to fear\n","And grace my Fears relieved\n","How precious did\n","That grace appear\n","The hour I first believed\n","Through many dangers\n","Toils and snares\n","We have already come\n","'Twas grace hath brought \n","Us safe thus far\n","And grace will lead us home\n","When we've been there \n","Ten thousand years\n","Bright shining as the sun\n","We'll have no less days to sing God's praise\n","Than when we first begun\n","Amazing grace \n","How sweet the sound\n","That saved a wretch like me\n","I once was lost \n","But now I'm found\n","Was blind, but now I see"]},{"cell_type":"code","metadata":{"id":"HietFhz2qwmq","executionInfo":{"elapsed":42700,"status":"ok","timestamp":1602963063571,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"},"user_tz":240},"outputId":"5747fba6-a04b-4cac-dff3-11ee0d49ba56","colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["model.stt(aud_int[0])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"may sangrado we the sound that seared like me i am as lost but i'm fond wasbashas grave that to my heart to feel angry smithia greedifist be through managers all annealed cottagers this far i unrequested my whole circuit she done poor sunshine as i find you are an was a burden oi'm found while husband bonnie\""]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"8qjhb8B0MYc9"},"source":["We can also try running the model on our augmented data as well."]},{"cell_type":"code","metadata":{"id":"iUWCV-HRMb3A","executionInfo":{"status":"ok","timestamp":1602965765304,"user_tz":240,"elapsed":133526,"user":{"displayName":"Sagar Saxena","photoUrl":"","userId":"06645006870975362026"}},"outputId":"d2d6a9e9-48eb-4919-d328-f26bdaacbdc7","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["for a in aud_aug:\n","    print(model.stt((a * 32768).astype(\"int16\")))"],"execution_count":52,"outputs":[{"output_type":"stream","text":["lanreath lying in a loonatic through his tales mealasabhal so he erisichthon was loud as in oi\n","all the generals her son tasseling i am sassoon was in osawatomie and smileth refineries in three haiatalnefous as are used this for i had sweethearts he and his army are circulation life as i and you iasion well sonnies\n","the bubble bayete have all fanfaronade wherefore lorraine live vaseline\n","may sangrado we the sound that seared like me i am as lost but i'm fond wasbashas grave that to my heart to feel angry smithia greedifist be through managers all annealed cottagers this far i unrequested my whole circuit she done pour sunshine as i find you are an was a burden oi'm found while husband bunny\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vDd3RU3rFx1c"},"source":["We can see that this model performs poorly on the audio for Amazing Grace. This is a negative outcome for the performance of DeepSpeech on its pretrained weights, but a positive outcome for showing that we could be introducing a more improved Speech To Text Model by exploring Music. It's also important to note, however, that DeepSpeech was probably not trained on music and that this outcome can be expected. A good future step would be to train DeepSpeech on music and see how if its performance improves."]}]}